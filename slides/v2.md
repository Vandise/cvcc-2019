# The New Science of Winning
## An Introduction to Data Science

---

# Who?

- Benjamin J. Anderson
- Contractor - Eau Claire Development LLC
- Chief Privacy Engineer - Viacom/CBS
- Instructor at CVTC
- github.com/Vandise
- Aspiring Data Scientist

^ Dozens of research papers, all of which have been inconclusive / failures

^ I like emulation and transforming data into information

---

# What?

- What is Data Science and why should I care?
- Who are Data Scientists?
- Technologies
- Statistical Analysis with R
- Supervised Machine Learning
	- Data Exploration, Transformation, Sanitization
	- Variable Selection
	- Model Definition and Training

---

# Suggested Readings

- Big Data In Practice, Bernard Marr

- Weapons of Math Destruction, Cathy O’Neil

- OpenIntro Statistics, Diez, Barr, Rundel ( Free PDF )

- Hands-On Recommendation Systems with Python, Rounak Banik

---

# Ground Rules

- Never believe what a statistician tells you
- Never believe in charts or graphs
	- you can make them say anything
- Polls / random sampling are an irresponsible representation of a population

——-

![inline](img/cell_phones.png)

——-

# So what is Data Science?

Textbook Definition:

- First defined in 1960 as “Datalogy”
- It’s a multi-disciplinary field like IT!
- It’s a “Buzzword”
- Traditionally called “Data Analyst”, “Mathematician”, “Statistician”, “DBA”
- Machine Learning is a small subset of the field

^ Datalogy - a combination of statistics and computer science

——-

# Why Should I Care?

- The worlds electronic data now exceeds 2.7 zettabytes (10^21)
- Anticipated to grow 60x that in the next decade
- Businesses are now collecting and storing junk/“big” data
- Cheap cloud computational resources allow the analyzation of “big” data
- Analyzation of “big” data often leads to competitive insights/gain
	- Can also be misleading i.e. Media “Pivot to Video”

^ Detect trends

^ Detect issues before they happen ( correlation / causation )

^ Prediction

——-

# Who are Data Scientists?

![inline](img/ds_intro_lead.png)

^ Forget everything the media and internet tells you

——-

# Who are Data Scientists Cont.

- Disciplined Mathematicians/Statisticians
- Often proficient in Data Warehousing and Querying Techniques
- Programming experience
	- Not often “Engineers”
- Data Delegates / Effective Communicators
- Intuitive

^ Intuitive problem solvers

^ Delegates: data presentation

——-

# Technologies

- R,  a funky array-based, statistical/functional programming language
- Python, Used because of its simplicity / ML support. Not always optimal in production
- SQL
- C, Java ( often in Production )
- Cloud Computing
	- ie Amazon Redshift, Google BigQuery

——-

# Maths
## A Statistics Refresher

![inline](img/frown_face.png)

——-

## Statistics - Normal Distributions & the Empirical Rule


![inline](img/norm_dist_emp.png)

——-

## Standard Deviation

- A quantity calculated to indicate the extent of deviation for a group as a whole

- The “spread” of data categorized into groups with the mean as the center point.

- Sigma ( σ ) for populations

- *s* for samples

——-

![inline](img/sd_formula.png)

- n = the total sample size
- x-hat is the sample mean

——-

## The Empirical Rule

- In Data Science, we aim for accurate models
	- 95% is usually aimed for, but not always achievable

- The Empirical Rule states that 99.7% of all the fall within three standard deviations of the mean.

- 95% is within 2 standard deviations
	- Meaning if our data follows a normal distribution, the mean for a dataset on a specific day, week, month, etc. is generally a good baseline.

——-

## Statistics - Variables

A value with variable results.

- Categorical ( Qualitative )
	- Multiple values / categorizations, often a set of Strings

- Boolean ( Qualitative )
	- True/False

- Quantitative
	- A value that can be counted

——-

## Statistics - Variables


- Dependent
	- The outcome of an analysis, determined by one or many variables

There are several other types of variables, but these are the most frequent.

——-

# Lets Build a Model!

——-

# Problem Statement

A bank would like to be able to identify current loans that are at risk of defaulting.

- Conservative Approach - bank misses out on potential profit, but limits losses on loan defaults

- Aggressive Approach - bank doesn’t miss potential profits, but loses profits on loan defaults

——-

# So what do we do?

Depends on the clients requirements.

- Optimize for profit ( aggressive model )
- Optimize for accuracy ( conservative model )

We’re going to build two different Models for both!

——-

# Getting to know you(r) data

Follow along with:

- r/1\_know\_your\_data.r

Recap:

- 50,000 loan applications
- 32 variables

——-

# Getting to know you(r) data cont.

- Variables with NA’s?
- Identify “bad” loans / loans at risk of defaulting
- What variable type are we using when identifying loans as good/bad?
	- categorization or boolean would work in this case

——-

# Loan Information

Follow along with:

- r/loan\_categorization.r

We have to change or create a categorization for the status variable:

- Charged Off = bad
- Default = bad
- Fully Paid = good
